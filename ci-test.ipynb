{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import itertools\n",
    "max_iter=[100,150,200,250,300]\n",
    "C=[1,1.5,2,2.5,3]\n",
    "grid=itertools.product(max_iter,C)\n",
    "grid=pd.DataFrame(grid,index=range(1,26),columns=[['max_iter','C']])\n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits(10)\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf= LogisticRegression( max_iter=grid.iloc[2,0]\n",
    "                             , C=grid.iloc[2,1]\n",
    "                             , random_state=101 )\n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_logr_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_logr_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score    = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "CI_1 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                       index=[\"Logistic Regression\"])\n",
    "CI_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ff594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import itertools\n",
    "max_depth=[4,6,8]\n",
    "min_samples_leaf=[4,5,6]\n",
    "ccp_alpha=[0.0001,0.001,0.01]\n",
    "grid=list(itertools.product(max_depth,min_samples_leaf,ccp_alpha))\n",
    "grid=pd.DataFrame(grid,index=range(1,28), columns=['max_depth','min_samples_leaf','ccp_alpha'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = DecisionTreeClassifier(max_depth=grid.loc[11,'max_depth'],\n",
    "                               min_samples_leaf=grid.loc[11,'min_samples_leaf'],\n",
    "                               ccp_alpha=grid.loc[11,'ccp_alpha'],random_state=101)\n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_class_tree_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_class_tree_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score    = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "CI_2 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['Decision Tree'])\n",
    "\n",
    "frames = [CI_1 , CI_2]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a44fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- Bagging\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import itertools\n",
    "n_estimators=[50,100,150,200,250]\n",
    "min_samples_leaf=[3,5,6,7,9]\n",
    "grid=list(itertools.product(n_estimators,min_samples_leaf))\n",
    "grid=pd.DataFrame(grid,index=range(1,26),columns=['n_estimators','min_samples_leaf'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = RandomForestClassifier(n_estimators=grid.loc[16,'n_estimators'],\n",
    "                           min_samples_leaf=grid.loc[16,'min_samples_leaf'],\n",
    "                           max_features=19,\n",
    "                           random_state=101)\n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_Bag_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_Bag_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "CI_3 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2348274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import itertools\n",
    "n_estimators=[50,100,150]\n",
    "max_depth=[4,5,6]\n",
    "min_samples_leaf=[3,5,7]\n",
    "max_features=[7,10,13]\n",
    "grid=list(itertools.product(n_estimators,max_depth,min_samples_leaf,max_features))\n",
    "grid=pd.DataFrame(grid,index=range(1,82),\n",
    "          columns=['n_estimators','max_depth','min_samples_leaf','max_features'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = RandomForestClassifier(n_estimators=grid.loc[79,'n_estimators'],\n",
    "                           max_depth=grid.loc[79,'max_depth'],\n",
    "                           min_samples_leaf=grid.loc[79,'min_samples_leaf'],\n",
    "                           max_features=grid.loc[79,'max_features'],\n",
    "                           random_state=101)   \n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_RFC_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_RFC_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "\n",
    "CI_4 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['Random Forest'])\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3 , CI_4]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49527c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5- LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr',n_components = None,shrinkage='auto')\n",
    "   \n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_lda_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_lda_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "\n",
    "CI_5 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['LDA'])\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3 , CI_4 , CI_5]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc0693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6- QDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = QuadraticDiscriminantAnalysis(reg_param=0.00001,store_covariance=True,tol=0.0001)\n",
    "   \n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_qda_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_qda_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "\n",
    "CI_6 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['QDA'])\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3 , CI_4 , CI_5 , CI_6]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e6620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7- Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = GaussianNB(var_smoothing=0)\n",
    "   \n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_GNB_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_GNB_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "\n",
    "CI_7 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['Naive Bayes'])\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3 , CI_4 , CI_5 , CI_6 , CI_7]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8- SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import itertools\n",
    "C=[1,1.5,2,2.5,3,3.5,4]\n",
    "kernel=['poly','rbf','sigmoid']\n",
    "gamma=['scale','auto']\n",
    "grid=itertools.product(C,kernel,gamma)\n",
    "grid=pd.DataFrame(grid,index=range(1,43),columns=['C','kernel','gamma'])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = SVC(  C=grid.loc[5,'C'],\n",
    "                kernel=grid.loc[5,'kernel'],\n",
    "                gamma=grid.loc[5,'gamma'],\n",
    "                random_state=101,\n",
    "                probability=True )\n",
    "   \n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_svc_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_svc_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "\n",
    "CI_8 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['SVM'])\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3 , CI_4 , CI_5 , CI_6 , CI_7 , CI_8]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc6f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9- knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import itertools\n",
    "n_neighbors=[3,4,5,6,7]\n",
    "weights=['uniform','distance']\n",
    "leaf_size=[25,30,35]\n",
    "grid=itertools.product(n_neighbors,weights,leaf_size)\n",
    "grid=pd.DataFrame(grid,index=range(1,31),columns=['n_neighbors','weights','leaf_size'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = KNeighborsClassifier(n_neighbors=grid.loc[22,'n_neighbors'], \n",
    "                               weights=grid.loc[22,'weights'],\n",
    "                               leaf_size=grid.loc[22,'leaf_size']\n",
    "                               )\n",
    "   \n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_knn_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_knn_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "\n",
    "CI_9 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['KNN'])\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3 , CI_4 , CI_5 , CI_6 , CI_7 , CI_8 , CI_9]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df45ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10- Gradient Boost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import itertools\n",
    "learning_rate=[0.1,0.01,0.001]\n",
    "n_estimators=[100,150,200,250]\n",
    "max_depth=[3,4,5]\n",
    "min_samples_leaf=[4,5,6]\n",
    "grid=itertools.product(learning_rate,n_estimators,max_depth,min_samples_leaf)\n",
    "grid=pd.DataFrame(grid,index=range(1,109),columns=['learning_rate','n_estimators',\n",
    "                                                   'max_depth','min_samples_leaf'])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = GradientBoostingClassifier(learning_rate=grid.loc[3,'learning_rate'],\n",
    "                                 n_estimators=grid.loc[3,'n_estimators'],\n",
    "                                 subsample=1,\n",
    "                                 max_depth=grid.loc[3,'max_depth'],\n",
    "                                 min_samples_leaf=grid.loc[3,'min_samples_leaf'],\n",
    "                                 random_state=101\n",
    "                            )\n",
    "   \n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_GBC_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_GBC_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "\n",
    "CI_10 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['Gradient Boost'])\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3 , CI_4 , CI_5 , CI_6 , CI_7 , CI_8 , CI_9 , CI_10]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ab632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11- Stocastic Gradient Boost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import itertools\n",
    "learning_rate=[0.1,0.01]\n",
    "n_estimators=[100,150,200,250]\n",
    "subsample=[0.5,0.7,0.9]\n",
    "max_depth=[3,4,5]\n",
    "min_samples_leaf=[4,5,6]\n",
    "grid=itertools.product(learning_rate,n_estimators,subsample,max_depth,min_samples_leaf)\n",
    "grid=pd.DataFrame(grid,index=range(1,217),columns=['learning_rate','n_estimators',\n",
    "                                                   'subsample','max_depth','min_samples_leaf'])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = GradientBoostingClassifier(learning_rate=grid.loc[148,'learning_rate'],\n",
    "                                  n_estimators=grid.loc[148,'n_estimators'],\n",
    "                                  subsample=grid.loc[148,'subsample'],\n",
    "                                  max_depth=grid.loc[148,'max_depth'],\n",
    "                                  min_samples_leaf=grid.loc[148,'min_samples_leaf'],\n",
    "                                  random_state=101\n",
    "                             )\n",
    "   \n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_SGBC_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_SGBC_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "\n",
    "CI_11 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['Stocastic Gradient Boost'])\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3 , CI_4 , CI_5 , CI_6 , CI_7 , CI_8 , CI_9 , CI_10 , CI_11]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ff2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12- XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import itertools\n",
    "max_depth=[3,4,5]\n",
    "learning_rate=[0.1,0.05,0.01]\n",
    "subsample=[0.5,0.7,0.9]\n",
    "reg_lambda=[0.1,0.05,0.01]\n",
    "grid=list(itertools.product(max_depth,learning_rate,subsample,reg_lambda))\n",
    "grid=pd.DataFrame(grid,index=range(1,82),\n",
    "                  columns=['max_depth','learning_rate','subsample','reg_lambda'])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = XGBClassifier( max_depth=grid.loc[16,'max_depth'],\n",
    "                         learning_rate=grid.loc[16,'learning_rate'],\n",
    "                         subsample=grid.loc[16,'subsample'],\n",
    "                         reg_lambda=grid.loc[16,'reg_lambda'],\n",
    "                         random_state=101\n",
    "                        )\n",
    "   \n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_XGB_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_XGB_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "\n",
    "CI_12 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['XGBoost'])\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3 , CI_4 , CI_5 , CI_6 , CI_7 , CI_8 , CI_9 , CI_10 , CI_11 , CI_12]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8970bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13- AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import itertools\n",
    "n_estimators=[50,100,150]\n",
    "learning_rate=[1,0.5,0.1]\n",
    "algorithm=['SAMME','SAMME.R']\n",
    "grid=list(itertools.product(n_estimators,learning_rate,algorithm))\n",
    "grid=pd.DataFrame(grid,index=range(1,19),\n",
    "                  columns=['n_estimators','learning_rate','algorithm'])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = AdaBoostClassifier(n_estimators=grid.loc[5,'n_estimators'],\n",
    "                             learning_rate=grid.loc[5,'learning_rate'],\n",
    "                             algorithm=grid.loc[5,'algorithm'],\n",
    "                             estimator=LogisticRegression( max_iter=100,\n",
    "                                                           C=2,\n",
    "                                                           random_state=101),\n",
    "                             random_state=101\n",
    "                             )\n",
    "   \n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_ABC_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_ABC_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "\n",
    "CI_13 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['AdaBoost'])\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3 , CI_4 , CI_5 , CI_6 , CI_7 , CI_8 , CI_9 , CI_10 , CI_11 , CI_12 , CI_13]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe060162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14- CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import itertools\n",
    "learning_rate = [0.03,0.07,0.1]\n",
    "depth = [4, 6, 8]\n",
    "l2_leaf_reg = [1, 3, 5]\n",
    "iterations = [50, 100, 150]\n",
    "grid=list(itertools.product(learning_rate,depth,l2_leaf_reg,iterations))\n",
    "grid=pd.DataFrame(grid,index=range(1,82),columns=['learning_rate','depth','l2_leaf_reg','iterations'])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:\n",
    "    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    clf = CatBoostClassifier(learning_rate=grid.loc[57,'learning_rate'],\n",
    "                          depth=grid.loc[57,'depth'],\n",
    "                          l2_leaf_reg=grid.loc[57,'l2_leaf_reg'],\n",
    "                          iterations=grid.loc[57,'iterations'],\n",
    "                          random_state=101,verbose=False)    \n",
    "    \n",
    "    clf.fit(X_train_LOOP, y_train_LOOP.values.ravel())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    pred_CATB_LOOP = clf.predict(X_test_LOOP)\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_CATB_LOOP)\n",
    "    \n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "\n",
    "CI_14 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['CatBoost'])\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3 , CI_4 , CI_5 , CI_6 , CI_7 , CI_8 , CI_9 , CI_10 , CI_11 , CI_12 , CI_13 , CI_14]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15- ANN\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "Accuracy_scores = []\n",
    "Precision_scores = []\n",
    "Sensitivity_scores = []\n",
    "Specificity_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "# Number of iterations for different train-test splits\n",
    "# Perform multiple train-test splits and calculate accuracy scores\n",
    "#for i in range(1,51):\n",
    "for i in [545,415,418,840,100,862,44,428,1201,1221,64,1224,31,101,424,77,285,435,269,737]:    \n",
    "    # 1_Split data into train and test sets\n",
    "    X_train_LOOP, X_test_LOOP, y_train_LOOP, y_test_LOOP = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # 2_Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    stsc_LOOP = StandardScaler()\n",
    "\n",
    "    # Fit on training set only & Apply transform to both the training set and the test set.\n",
    "    X_train_scaled_LOOP = stsc_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_scaled_LOOP = stsc_LOOP.transform(X_test_LOOP)\n",
    "\n",
    "    X_train_LOOP=pd.DataFrame(X_train_scaled_LOOP,index=X_train_LOOP.index,columns=X_train_LOOP.columns)\n",
    "    X_test_LOOP=pd.DataFrame(X_test_scaled_LOOP,index=X_test_LOOP.index,columns=X_test_LOOP.columns)\n",
    "    \n",
    "    # 3_impeliment pca\n",
    "    pca_LOOP = PCA(n_components=19)\n",
    "    X_train_pca_LOOP = pca_LOOP.fit_transform(X_train_LOOP)\n",
    "    X_test_pca_LOOP = pca_LOOP.transform(X_test_LOOP)\n",
    "    \n",
    "    X_train_LOOP = pd.DataFrame(X_train_pca_LOOP,index=X_train_LOOP.index, \n",
    "                                columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                         'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                         'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                         'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    X_test_LOOP = pd.DataFrame(X_test_pca_LOOP,index=X_test_LOOP.index,\n",
    "                               columns=['component_1', 'component_2', 'component_3', 'component_4', 'component_5',\n",
    "                                        'component_6', 'component_7', 'component_8','component_9', 'component_10',\n",
    "                                        'component_11', 'component_12', 'component_13','component_14', 'component_15',\n",
    "                                        'component_16', 'component_17', 'component_18', 'component_19'])\n",
    "    \n",
    "    \n",
    "    # Initialize and train a classifier \n",
    "    import tensorflow as tf\n",
    "    tf.keras.utils.set_random_seed (143)\n",
    "\n",
    "    # Initializing Artificial Neural Network\n",
    "    ann = tf.keras.models.Sequential()# Creating Hidden Layers\n",
    "\n",
    "    #Adding First Hidden Layer\n",
    "    ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))\n",
    "    #Adding Second Hidden Layer\n",
    "    ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))\n",
    "\n",
    "    #Adding Output Layer\n",
    "    ann.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
    "\n",
    "    #Compiling ANN\n",
    "    ann.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['Accuracy'])  \n",
    "    \n",
    "    ann.fit(X_train_LOOP, y_train_LOOP.values.ravel(),batch_size=32,epochs = 100,verbose=False)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    ann.predict(X_test_LOOP)\n",
    "    anper=list(ann.predict(X_test_LOOP)>0.5)\n",
    "    [int(elem) for elem in anper]\n",
    "    pred_ann_LOOP = np.array([int(elem) for elem in anper])\n",
    "\n",
    "    \n",
    "    C_M=confusion_matrix(y_test_LOOP,pred_ann_LOOP)\n",
    "    TN=C_M[0,0]\n",
    "    TP=C_M[1,1]\n",
    "    FN=C_M[1,0]\n",
    "    FP=C_M[0,1]\n",
    "    \n",
    "    # Calculate metrics \n",
    "    # Accuracy = accuracy_score(y_test_LOOP, pred_svc_LOOP)\n",
    "    Accuracy = (TN+TP)/(TP+TN+FN+FP)\n",
    "    Precision = TP/(TP+FP),\n",
    "    Sensitivity =TP/(TP+FN),\n",
    "    Specificity =TN/(TN+FP),\n",
    "    F1_score = 2/((1/(TP/(TP+FP)))+(1/(TP/(TP+FN))))\n",
    "    \n",
    "    Accuracy_scores.append(Accuracy)\n",
    "    Precision_scores.append(Precision)\n",
    "    Sensitivity_scores.append(Sensitivity)\n",
    "    Specificity_scores.append(Specificity)\n",
    "    F1_scores.append(F1_score)\n",
    "    \n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_Accuracy = np.mean(Accuracy_scores)\n",
    "std_Accuracy = np.std(Accuracy_scores)\n",
    "\n",
    "mean_Precision = np.mean(Precision_scores)\n",
    "std_Precision = np.std(Precision_scores)\n",
    "\n",
    "mean_Sensitivity = np.mean(Sensitivity_scores)\n",
    "std_Sensitivity = np.std(Sensitivity_scores)\n",
    "\n",
    "mean_Specificity = np.mean(Specificity_scores)\n",
    "std_Specificity = np.std(Specificity_scores)\n",
    "\n",
    "mean_F1_score = np.mean(F1_scores)\n",
    "std_F1_score = np.std(F1_scores)\n",
    "\n",
    "\n",
    "# Calculate confidence interval (e.g., 95% confidence interval)\n",
    "confidence_interval_Accuracy    = (mean_Accuracy - 1.96 * std_Accuracy, mean_Accuracy + 1.96 * std_Accuracy)\n",
    "confidence_interval_Precision   = (mean_Precision - 1.96 * std_Precision, mean_Precision + 1.96 * std_Precision)\n",
    "confidence_interval_Sensitivity = (mean_Sensitivity - 1.96 * std_Sensitivity, mean_Sensitivity + 1.96 * std_Sensitivity)\n",
    "confidence_interval_Specificity = (mean_Specificity - 1.96 * std_Specificity, mean_Specificity + 1.96 * std_Specificity)\n",
    "confidence_interval_F1_score   = (mean_F1_score - 1.96 * std_F1_score, mean_F1_score + 1.96 * std_F1_score)\n",
    "\n",
    "#print(f\"Accuracy_scores: {Accuracy_scores:.4f}\")\n",
    "print(f\"mean_Accuracy: {mean_Accuracy:.4f}\")\n",
    "print(f\"std_Accuracy: {std_Accuracy:.4f}\")\n",
    "print(f\"confidence_interval_Accuracy: {confidence_interval_Accuracy}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Precision_scores: {Precision_scores:.4f}\")\n",
    "print(f\"mean_Precision: {mean_Precision:.4f}\")\n",
    "print(f\"std_Precision: {std_Precision:.4f}\")\n",
    "print(f\"confidence_interval_Precision: {confidence_interval_Precision}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Sensitivity_scores: {Sensitivity_scores:.4f}\")\n",
    "print(f\"mean_Sensitivity: {mean_Sensitivity:.4f}\")\n",
    "print(f\"std_Sensitivity: {std_Sensitivity:.4f}\")\n",
    "print(f\"confidence_interval_Sensitivity: {confidence_interval_Sensitivity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"Specificity_scores: {Specificity_scores:.4f}\")\n",
    "print(f\"mean_Specificity: {mean_Specificity:.4f}\")\n",
    "print(f\"std_Specificity: {std_Specificity:.4f}\")\n",
    "print(f\"confidence_interval_Specificity: {confidence_interval_Specificity}\")\n",
    "print('\\n')\n",
    "\n",
    "#print(f\"F1_scores: {F1_scores:.4f}\")\n",
    "print(f\"mean_F1_score: {mean_F1_score:.4f}\")\n",
    "print(f\"std_F1_score: {std_F1_score:.4f}\")\n",
    "print(f\"confidence_interval_F1_score: {confidence_interval_F1_score}\")\n",
    "\n",
    "\n",
    "CI_15 = pd.DataFrame({ 'Accuracy'    : f\"{mean_Accuracy:.4f} ± ({std_Accuracy*1.96 :.2f})\",\n",
    "                      'Precision'   : f\"{mean_Precision:.4f} ± ({std_Precision*1.96 :.2f})\",\n",
    "                      'Sensitivity' : f\"{mean_Sensitivity:.4f} ± ({std_Sensitivity*1.96 :.2f})\",\n",
    "                      'Specificity' : f\"{mean_Specificity:.4f} ± ({mean_Specificity*1.96 :.2f})\",\n",
    "                      'F1-score'    : f\"{mean_F1_score:.4f} ± ({std_F1_score*1.96 :.2f})\" },\n",
    "                      index=['ANN'])\n",
    "\n",
    "frames = [CI_1 , CI_2 , CI_3 , CI_4 , CI_5 , CI_6 , CI_7 , CI_8 , CI_9 , CI_10 , CI_11 , CI_12 , CI_13 , CI_14 , CI_15]\n",
    "\n",
    "CI_FOR_MODELS = pd.concat(frames)\n",
    "CI_FOR_MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f993a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_FOR_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5e95d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello word\n"
     ]
    }
   ],
   "source": [
    "print('hello word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9be2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
